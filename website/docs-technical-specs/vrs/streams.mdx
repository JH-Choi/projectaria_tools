---
sidebar_position: 0
title: VRS Format
---
# Project Aria VRS Format

Project Aria data is stored in [VRS](https://facebookresearch.github.io/vrs/), which is optimized to record and playback streams of multi-modal sensor data, such as images, audio, and other discrete sensors (IMU, temperature, etc.).
In this page, we will introduce some basic concepts of `VRS` file format in Aria recordings.
Users are referred to the official [`VRS` repo documentation page](https://facebookresearch.github.io/vrs/) for details.

## Aria data streams
In VRS, data is organized by streams, each storing data measured by a specific sensor, or calculated from an on-device machine perception algorithm.

The VRS streams are uniquely identified by their `StreamId`, each consisting of a `RecordableTypeId` to categorize the type of the stream data, and an `InstanceId` for identifying the specific instance of the sensor.
For example, the first SLAM camera is identified with `StreamId = 1201-1`, where `1201` is the numerical ID for SLAM camera data type, and `-1` identifies the first of all the SLAM cameras.

For convenience, we also provide a short label for each stream within our library `projectaria-tools`, which provides a human-readable way to access the data.
See [this page](/docs-technical-specs/projectariatools/streamid-label-mapper.mdx) to learn more.

## Aria sensor data and configuration
Sensor data includes:
* Sensor readout
* Timestamps
* Acquisition parameters (exposure and gain settings)
* Conditions (e.g. temperature) during data collection

Most sensor data of a single stream and at a specific timestamp is stored as a single piece, except for image and audio.

### How data is stored for image recordings
* Each camera stores a single image frame at a time.
* The image frame contains two parts, the image itself and the image record.
    * The image record stores timestamps, frame id, and acquisition parameters, such as exposure and gain. This avoids having to read image data to get the information in the record.

### How data is stored for audio recordings

* The audio data is grouped into data chunks of 4096 audio samples from all microphones.
* Each chunk contains two parts, the data part for the audio signal, and the report part for the timestamps of each audio signal.

### Sensor configuration blob

The sensor configuration blob stores the static information of a stream. Common sensor configuration stores information, such as sensor model, sensor serial (if available) as well as frame rate.
Stream-specific information, such as image resolution, is also stored in configurations.

Go to this [python tutorial](/research-tools/projectariatools/pythontutorials/queue) to learn how to access and use the sensor data using Python data utilities.
Go to the [source code](https://github.com/facebookresearch/projectaria_tools/blob/main/core/data_provider/players) for the detailed implementation of sensor data and configurations.

## Useful VRS tools

* The most intuitive way to access Aria VRS files is via the tools (and APIs) shipped in [`projectaria-tools` library](/research-tools/projectariatools/start), which includes tools to [visualize Aria VRS](/research-tools/projectariatools/tools/pythonviz), [convert to MP4](/research-tools/projectariatools/tools/vrstomp4), and [export to other data format](/research-tools/projectariatools/tools/exportcsv).
* Users can inspect the data quality of Aria VRS file using [`VrsHealthCheck`](/ark/vrs_health_check/installation), which is a tool that we specially tailored for Aria VRS recordings.
* Users can also choose to use [the native tool provided by the `VRS` library](https://facebookresearch.github.io/vrs/) to perform some simple actions on the VRS file, including inspecting basic data information, extracting to images or audio files, etc. But please note that the `VRS` library needs to be [built with H.265 decoding support](https://github.com/facebookresearch/vrs#build--run-with-h265-hevc-decoding-support-macos--linux) in order to properly handle Aria Gen2 VRS files.
